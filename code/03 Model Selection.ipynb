{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: The Persuasive Power of Words\n",
    "\n",
    "*by Nee Bimin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3: Model Selection\n",
    "\n",
    "In this notebook, we will run a few models to select the production model for testing in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "- [Read Data](#Read-Data)\n",
    "- [Persuasive Classifier](#Persuasive-Words-Classifier)\n",
    "    * [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Inspiring Classifier](#Persuasive-Words-Classifier)\n",
    "    * [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Unconvincing Classifier](#Persuasive-Words-Classifier)\n",
    "    * [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Multilabel Classifier](#Multilabel-Classifier)\n",
    "    * [Train/Test Split](#Train/Test-Split)\n",
    "    * [Linear SVC](#Linear-SVC)\n",
    "    * [Naive Bayes](#Naive-Bayes)\n",
    "    * [Logistic Regression](#Logistic-Regression)\n",
    "- [Model Evaluation](#Model-Evaluation)\n",
    "    * [Parsing Data](#Parsing-Data)\n",
    "    * [Preprocessing](#Preprocessing)\n",
    "- [Conclusion-and-Recommendations](#Conclusion-and-Recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Import libraries for modeling\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Import libraries for parsing html\n",
    "import bs4 as bs \n",
    "import soupsieve as sv # Soup Sieve to parse using CSS selector\n",
    "import codecs # To read in HTML file\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "ted_model = pd.read_csv('../data/ted_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>views</th>\n",
       "      <th>transcript</th>\n",
       "      <th>persuasive_label</th>\n",
       "      <th>inspiring_label</th>\n",
       "      <th>unconvincing_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>47227110</td>\n",
       "      <td>good morning great ive blown away whole thing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>3200520</td>\n",
       "      <td>thank much chris truly great honor opportunity...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>1636292</td>\n",
       "      <td>hello voice mail old friend ive called tech su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>1697550</td>\n",
       "      <td>today im happy heard sustainable development s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>12005869</td>\n",
       "      <td>10 year ago took task teach global development...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments     views                                         transcript  \\\n",
       "0      4553  47227110  good morning great ive blown away whole thing ...   \n",
       "1       265   3200520  thank much chris truly great honor opportunity...   \n",
       "2       124   1636292  hello voice mail old friend ive called tech su...   \n",
       "3       200   1697550  today im happy heard sustainable development s...   \n",
       "4       593  12005869  10 year ago took task teach global development...   \n",
       "\n",
       "   persuasive_label  inspiring_label  unconvincing_label  \n",
       "0                 1                1                   1  \n",
       "1                 1                1                   1  \n",
       "2                 1                0                   1  \n",
       "3                 1                1                   1  \n",
       "4                 1                1                   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are talks that have more than one label i.e. received at least the median number of votes for more than one type of rating. So we cannot train the model based on multi-class text classification. Rather we will train the model separately for each label to find out the common words in the talks that are voted persuasive, inspiring and unconvincing. \n",
    "\n",
    "After training the models separately for each label, we will compare their performance against multilabel classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persuasive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ted_model.transcript\n",
    "y = ted_model.persuasive_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5020337013364323"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "baseline = y_train.value_counts(normalize=True)[1]\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find the baseline accuracy, which is the likelihood of a transcript having a higher than median number of persuasive votes, by calculating the percentage of the dataset that has the target value of 1. Normalising the value counts shows the percentage, and gives a baseline accuracy of 50.06%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = [ # list of pipeline steps for each model combo\n",
    "    [('tf',TfidfVectorizer()), ('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()), ('svm', SGDClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('xgb', XGBClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('rf', RandomForestClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('scaler', StandardScaler(with_mean=False)), ('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','svm','xgb','rf','logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = [\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>baseline_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, baseline_accuracy, recall, precision, f1-score]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "gs_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','baseline_accuracy',\n",
    "                                   'recall', 'precision', 'f1-score'])\n",
    "gs_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.821615339918652 \n",
      "\n",
      "0.6869918699186992 \n",
      "\n",
      "True Negatives: 158\n",
      "False Positives: 209\n",
      "False Negatives: 22\n",
      "True Positives: 349 \n",
      "\n",
      "Model:  svm\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "1.0 \n",
      "\n",
      "0.7235772357723578 \n",
      "\n",
      "True Negatives: 225\n",
      "False Positives: 142\n",
      "False Negatives: 62\n",
      "True Positives: 309 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    gs_results = gs_results.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine performed the best based on test set accuracy, our main metric. It is closely followed by Logistic Regression. While Naive Bayes has the highest f1-score, we will proceed with hyperparameter tuning for Logistic Regression and Support Vector Machine since accuracy is our main metric of evaluation.\n",
    "\n",
    "Interestingly, SVM, Random Forest and Logistic Regression all had a training accuracy of 1, suggesting severe overfitting of the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store results for tuning\n",
    "persuasive_tuning = pd.DataFrame(columns=['model', 'best_params','train_accuracy','test_accuracy','recall',\n",
    "                                 'precision','f1-score'])\n",
    "\n",
    "persuasive_tuning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_steps = [ # list of pipeline steps with best params from earlier run\n",
    "    [('tf',TfidfVectorizer(ngram_range=(1,2), stop_words='english')), ('svm', SGDClassifier())],\n",
    "    [('tf',TfidfVectorizer(ngram_range=(1,1), stop_words='english')), ('scaler', StandardScaler(with_mean=False)), \n",
    "     ('logreg', LogisticRegression())]\n",
    "]\n",
    "\n",
    "persuasive_models = ['svm', 'logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Randomized Search using Pipeline, formatted to call named estimators\n",
    "persuasive_params = [{'tf__max_features': [None, 1000, 2500],\n",
    "                      'tf__min_df': [1, 2], \n",
    "                      'tf__max_df': [0.7, 1.0],\n",
    "                      'svm__penalty': ['l1', 'l2'],\n",
    "                      'svm__loss': ['perceptron', 'log'],\n",
    "                      'svm__alpha': [0.001, 0.01],\n",
    "                      'svm__max_iter': [5, 1000],\n",
    "                      'svm__early_stopping': [True, False],\n",
    "                      'svm__tol': [0.001, 0.0001]},\n",
    "                     {'tf__max_features': [None, 2500, 3000],\n",
    "                      'tf__min_df': [1, 2], \n",
    "                      'tf__max_df': [1.0, 1.2],\n",
    "                      'logreg__max_iter': [100, 105],\n",
    "                      'logreg__C': [3.0, 4.0, 5.0],\n",
    "                      'logreg__penalty': ['l1', 'l2'],\n",
    "                      'logreg__solver': ['saga', 'liblinear']}\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(persuasive_models)):\n",
    "    # instantiate pipeline \n",
    "    persuasive_pipe = Pipeline(steps=persuasive_steps[i])\n",
    "    # fit RandomizedSearchCV to model and model's params\n",
    "    persuasive_rs = RandomizedSearchCV(n_iter=50, estimator=persuasive_pipe, \n",
    "                                       param_distributions=persuasive_params[i],\n",
    "                                       cv=3, random_state=42, verbose=1, n_jobs=-1) \n",
    "\n",
    "    persuasive_results = {}\n",
    "\n",
    "    persuasive_rs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', persuasive_models[i])\n",
    "    persuasive_results['model'] = persuasive_models[i]\n",
    "\n",
    "    print('Best Params: ', persuasive_rs.best_params_)\n",
    "    persuasive_results['best_params'] = persuasive_rs.best_params_\n",
    "\n",
    "    print(persuasive_rs.score(X_train, y_train), '\\n')\n",
    "    persuasive_results['train_accuracy'] = persuasive_rs.score(X_train, y_train)\n",
    "    \n",
    "    print(persuasive_rs.score(X_test, y_test), '\\n')\n",
    "    persuasive_results['test_accuracy'] = persuasive_rs.score(X_test, y_test)\n",
    "    \n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, persuasive_rs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    persuasive_results['recall'] = tp/(tp+fn)\n",
    "    persuasive_results['precision'] = tp/(tp+fp)\n",
    "    persuasive_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    persuasive_tuning = persuasive_tuning.append(persuasive_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_tuning.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning, SVM is still the better performer than Logistic Regression, with higher accuracy, recall, precision and f1 on the test set. Overfitting has also been reduced. This model will be the production model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiring Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ted_model.transcript\n",
    "y = ted_model.inspiring_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy\n",
    "baseline = y_train.value_counts(normalize=True)[1]\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = [ # list of pipeline steps for each model combo\n",
    "    [('tf',TfidfVectorizer()), ('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()), ('svm', SGDClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('xgb', XGBClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('rf', RandomForestClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('scaler', StandardScaler(with_mean=False)), ('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','svm','xgb','rf','logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = [\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate results DataFrame\n",
    "gs_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','baseline_accuracy',\n",
    "                                   'recall', 'precision', 'f1-score'])\n",
    "gs_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    gs_results = gs_results.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_results.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing models are again SVM and Logistic Regression by test set accuracy. We see again that Logistic Regression, SVM and Random Forest all have training set accuracy of 1. Similar to persuasive words, the best parameter for SVM is a bigram.\n",
    "Hyperparameter tuning will be done for Logistic Regression and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store results for tuning\n",
    "inspiring_tuning = pd.DataFrame(columns=['model', 'best_params','train_accuracy','test_accuracy','recall',\n",
    "                                         'precision','f1-score'])\n",
    "\n",
    "inspiring_tuning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspiring_steps = [ # list of pipeline steps with best params from earlier runs\n",
    "    [('tf',TfidfVectorizer(ngram_range=(1,2), stop_words='english')), ('scaler', StandardScaler(with_mean=False)), \n",
    "     ('logreg',LogisticRegression())],\n",
    "    [('tf',TfidfVectorizer(ngram_range=(1,2), stop_words='english')), ('svm', SGDClassifier())]\n",
    "]\n",
    "\n",
    "inspiring_models = ['logreg','svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline, formatted to call named estimators\n",
    "inspiring_params = [{'tf__max_features': [None, 2500, 3000],\n",
    "                      'tf__min_df': [1, 2], \n",
    "                      'tf__max_df': [0.8, 0.9, 1.0],\n",
    "                      'logreg__max_iter': [80, 100],\n",
    "                      'logreg__C': [2.0, 25, 3.0],\n",
    "                      'logreg__penalty': ['l1', 'l2'],\n",
    "                      'logreg__solver': ['saga', 'liblinear']},\n",
    "                    {'tf__max_features': [None, 1000, 1200],\n",
    "                      'tf__min_df': [1, 2], \n",
    "                      'tf__max_df': [0.75, 0.8, 1.0],\n",
    "                      'svm__penalty': ['l1', 'l2'],\n",
    "                      'svm__loss': ['hinge', 'log'],\n",
    "                      'svm__alpha': [0.0001, 0.001, 0.01],\n",
    "                      'svm__max_iter': [1000, 1200],\n",
    "                      'svm__early_stopping': [True, False],\n",
    "                      'svm__tol': [0.001, 0.0001]}\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(inspiring_models)):\n",
    "    # instantiate pipeline \n",
    "    inspiring_pipe = Pipeline(steps=inspiring_steps[i])\n",
    "    # fit RandomizedSearchCV to model and model's params\n",
    "    inspiring_rs = RandomizedSearchCV(n_iter=50, estimator=inspiring_pipe, \n",
    "                                      param_distributions=inspiring_params[i],\n",
    "                                      cv=3, random_state=42, verbose=1, n_jobs=-1) \n",
    "\n",
    "    inspiring_results = {}\n",
    "\n",
    "    inspiring_rs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', inspiring_models[i])\n",
    "    inspiring_results['model'] = inspiring_models[i]\n",
    "\n",
    "    print('Best Params: ', inspiring_rs.best_params_)\n",
    "    inspiring_results['best_params'] = inspiring_rs.best_params_\n",
    "\n",
    "    print(inspiring_rs.score(X_train, y_train), '\\n')\n",
    "    inspiring_results['train_accuracy'] = inspiring_rs.score(X_train, y_train)\n",
    "    \n",
    "    print(inspiring_rs.score(X_test, y_test), '\\n')\n",
    "    inspiring_results['test_accuracy'] = inspiring_rs.score(X_test, y_test)\n",
    "    \n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, inspiring_rs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    inspiring_results['recall'] = tp/(tp+fn)\n",
    "    inspiring_results['precision'] = tp/(tp+fp)\n",
    "    inspiring_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    inspiring_tuning = inspiring_tuning.append(inspiring_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspiring_tuning.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuning only resulted in a marginal improvement of test accuracy for SVM and made it worse for Logistic Regression. The SVM will be chosen as the production model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconvincing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ted_model.transcript\n",
    "y = ted_model.unconvincing_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy\n",
    "baseline = y_train.value_counts(normalize=True)[1]\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = [ # list of pipeline steps for each model combo\n",
    "    [('tf',TfidfVectorizer()), ('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()), ('svm', SGDClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('xgb', XGBClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('rf', RandomForestClassifier())],\n",
    "    [('tf',TfidfVectorizer()), ('scaler', StandardScaler(with_mean=False)), ('logreg',LogisticRegression())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','svm','xgb','rf','logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = [\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate results DataFrame\n",
    "gs_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','baseline_accuracy',\n",
    "                                         'recall', 'precision', 'f1-score'])\n",
    "gs_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(steps_list)):\n",
    "    # instantiate pipeline \n",
    "    pipe = Pipeline(steps=steps_list[i])\n",
    "    # fit GridSearchCV to model and model's params\n",
    "    gs = GridSearchCV(pipe, pipe_params[i], cv=3) \n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', gs.best_params_)\n",
    "    model_results['best_params'] = gs.best_params_\n",
    "\n",
    "    print(gs.score(X_train, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = gs.score(X_train, y_train)\n",
    "    \n",
    "    print(gs.score(X_test, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = gs.score(X_test, y_test)\n",
    "    \n",
    "    model_results['baseline_accuracy'] = baseline\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    model_results['recall'] = tp/(tp+fn)\n",
    "    model_results['precision'] = tp/(tp+fp)\n",
    "    model_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    gs_results = gs_results.append(model_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM and Logistic Regression have the highest test accuracy. Hyperparameter tuning will be done for these two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store results for tuning\n",
    "unconvincing_tuning = pd.DataFrame(columns=['model', 'best_params','train_accuracy','test_accuracy','recall',\n",
    "                                 'precision','f1-score'])\n",
    "\n",
    "unconvincing_tuning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconvincing_steps = [ # list of pipeline steps with best params from earlier run\n",
    "    [('tf',TfidfVectorizer(ngram_range=(1,2), stop_words='english')), ('svm', SGDClassifier(tol=None))],\n",
    "    [('tf',TfidfVectorizer(ngram_range=(1,2), stop_words='english')), ('scaler', StandardScaler(with_mean=False)), \n",
    "     ('logreg',LogisticRegression())]\n",
    "]\n",
    "\n",
    "unconvincing_models = ['svm','logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline, formatted to call named estimators\n",
    "\n",
    "unconvincing_params = [{'tf__max_features': [None, 800, 1000],\n",
    "                        'tf__min_df': [1, 2], \n",
    "                        'tf__max_df': [0.75, 1.0],\n",
    "                        'svm__penalty': ['l1', 'l2'],\n",
    "                        'svm__loss': ['hinge', 'log'],\n",
    "                        'svm__alpha': [0.0001, 0.001, 0.01],\n",
    "                        'svm__max_iter': [1000, 1200],\n",
    "                        'svm__early_stopping': [True, False],\n",
    "                        'svm__tol': [0.001, 0.0001]},\n",
    "                       {'tf__max_features': [None, 2500, 3000],\n",
    "                        'tf__min_df': [1, 2], \n",
    "                        'tf__max_df': [0.8, 0.9, 1.0],\n",
    "                        'logreg__max_iter': [80, 100],\n",
    "                        'logreg__C': [2.0, 25, 3.0],\n",
    "                        'logreg__penalty': ['l1', 'l2'],\n",
    "                        'logreg__solver': ['saga', 'liblinear']}\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through index of number of steps\n",
    "for i in range(len(unconvincing_models)):\n",
    "    # instantiate pipeline \n",
    "    unconvincing_pipe = Pipeline(steps=unconvincing_steps[i])\n",
    "    # fit RandomizedSearch to model and model's params\n",
    "    unconvincing_rs = RandomizedSearchCV(n_iter=50, estimator=unconvincing_pipe, \n",
    "                                         param_distributions=unconvincing_params[i],\n",
    "                                         cv=3, random_state=42, verbose=1, n_jobs=-1) \n",
    "\n",
    "    unconvincing_results = {}\n",
    "\n",
    "    unconvincing_rs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Model: ', unconvincing_models[i])\n",
    "    unconvincing_results['model'] = unconvincing_models[i]\n",
    "\n",
    "    print('Best Params: ', unconvincing_rs.best_params_)\n",
    "    unconvincing_results['best_params'] = unconvincing_rs.best_params_\n",
    "\n",
    "    print(unconvincing_rs.score(X_train, y_train), '\\n')\n",
    "    unconvincing_results['train_accuracy'] = unconvincing_rs.score(X_train, y_train)\n",
    "    \n",
    "    print(unconvincing_rs.score(X_test, y_test), '\\n')\n",
    "    unconvincing_results['test_accuracy'] = unconvincing_rs.score(X_test, y_test)\n",
    "    \n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, unconvincing_rs.predict(X_test)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    \n",
    "    unconvincing_results['recall'] = tp/(tp+fn)\n",
    "    unconvincing_results['precision'] = tp/(tp+fp)\n",
    "    unconvincing_results['f1-score'] = 2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))\n",
    "\n",
    "    unconvincing_tuning = unconvincing_tuning.append(unconvincing_results, ignore_index=True)\n",
    "    pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconvincing_tuning.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the inspiring classifier, SVM performed better here after hyperparameter tuning. This will be our production model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classification\n",
    "\n",
    "Multilabel classification is a problem where multiple target labels can be assigned to each observation instead of only one. This is the exact situation we are facing now with more than one label assigned to some of the talks. \n",
    "\n",
    "For this problem, the models that will be run are Naive Bayes and Support Vector Machine with OneVsRest wrapper that can be used for multilabel learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['persuasive_label', 'inspiring_label', 'unconvincing_label']\n",
    "\n",
    "train, test = train_test_split(ted_model, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train.transcript\n",
    "X_test = test.transcript\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for label in labels:\n",
    "    print('Processing {}'.format(label))\n",
    "    # train the model using X_train and y_train\n",
    "    svc_pipeline.fit(X_train, train[label])\n",
    "    # compute the testing accuracy\n",
    "    prediction = svc_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[label], prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)),\n",
    "            ])\n",
    "\n",
    "for label in labels:\n",
    "    print('Processing {}'.format(label))\n",
    "    # train the model using X_train and y_train\n",
    "    nb_pipeline.fit(X_train, train[label])\n",
    "    # compute the testing accuracy\n",
    "    prediction = nb_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[label], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    logreg_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = logreg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Data\n",
    "The html has been downloaded from the website https://highspark.co/famous-persuasive-speeches/ containing an all-time 40 famous persuasive speeches. The speeches will be tested using the models developed above. Beautiful Soup will be used to parse the html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Raw.html and parse into bs4 format\n",
    "raw = codecs.open(\"../data/Raw.html\", \"r\", \"utf-8\").read()\n",
    "print(raw)\n",
    "soup = bs.BeautifulSoup(raw,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get main div where all the quotes are\n",
    "body = soup.select(\".et_pb_module.et_pb_post_content.et_pb_post_content_0_tb_body\")\n",
    "# To find all the titles of the quotes\n",
    "h2 = body[0].find_all(\"h2\")\n",
    "# To find all the quotes\n",
    "blockquotes = body[0].find_all(\"blockquote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove non-text characters from the quote\n",
    "def get_text_from_blockquote(blockquote):\n",
    "    Quote = \"\"\n",
    "    for p in blockquote.find_all(\"p\"):\n",
    "        Quote += p.get_text().strip().replace(\"\\r\\n\",\" \")\n",
    "    return re.sub(\"\\s{2,}\", \" \", Quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = pd.DataFrame()\n",
    "# Putting the title and articles into a dataframe\n",
    "speeches['title'] = h2\n",
    "speeches['speech'] = blockquotes\n",
    "\n",
    "# Clean up titles and articles\n",
    "speeches['title'] = speeches['title'].apply(lambda x: re.sub(\"\\d+.\",\"\",x.get_text())) # Use regex to remove index that comes with the title\n",
    "speeches['speech'] = speeches['speech'].apply(get_text_from_blockquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmastop(word):\n",
    "    # Instantiate Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    #remove if words from stoplist or words with http or '/' in it\n",
    "    if word in stopwords.words('english') or 'http' in word or '/' in word:\n",
    "        word = ''\n",
    "        \n",
    "    # Lemmatize word then remove any non word characters not catched in previous steps\n",
    "    p_word = re.sub('\\W+', '',lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # returns processed words\n",
    "    return p_word\n",
    "\n",
    "def clean_data(raw_string):\n",
    "    # The input is raw unprocessed text), and \n",
    "    # the output is preprocessed text)\n",
    "    # Instantiate Tokenizer. \n",
    "    tokenizer = RegexpTokenizer(r'\\w+\\'?\\w+(?=\\W)') # Regex matches words and words with apostrophe in between\n",
    "    \n",
    "    # Tokenize raw string\n",
    "    tokens = tokenizer.tokenize(raw_string.lower())  \n",
    "    \n",
    "    # call function to remove stop list words and lemmatize words\n",
    "    processed_tokens = map(lemmastop, tokens)\n",
    "    \n",
    "    # Joins only tokens with words and returns processed string\n",
    "    return ' '.join(token for token in processed_tokens if token != '')\n",
    "\n",
    "speeches['speech'] = speeches['speech'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the speeches are supposed to be the 40 most persuasive and inspiring speeches of all time, we will add columns for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches['persuasive_label'] = 1\n",
    "speeches['inspiring_label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persuasive Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ted_model.transcript\n",
    "y_train = ted_model.persuasive_label\n",
    "\n",
    "X_test = speeches.speech\n",
    "y_test = speeches.persuasive_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the best parameters to instantiate model\n",
    "persuasive_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with best parameters.\n",
    "tf_final = TfidfVectorizer(min_df=2, max_features=2500, max_df=0.7, \n",
    "                           stop_words='english', ngram_range=(1,2))\n",
    "X_train_final = tf_final.fit_transform(X_train)\n",
    "X_test_final = tf_final.transform(X_test)\n",
    "\n",
    "# Fit model.\n",
    "svm_final = SGDClassifier(penalty='l2', max_iter=5, loss='log', alpha=0.001, random_state=42)\n",
    "svm_final.fit(X_train_final, y_train)\n",
    "print('Test set accuracy score: ', svm_final.score(X_test_final, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = svm_final.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame(speeches['title'])\n",
    "model_eval['speech'] = X_test\n",
    "model_eval['label'] = y_test\n",
    "model_eval['predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe\n",
    "model_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out the incorrecly predicted ones\n",
    "persuasive_inaccurate = model_eval[model_eval['predictions'] == 0]\n",
    "persuasive_inaccurate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to TFIDF vectorize and place the count of words into a dataframe\n",
    "def count_words(data, num):\n",
    "    \n",
    "    # Instantiate TFIDF Vectorizer with stopwords to remove them\n",
    "    tf = TfidfVectorizer(stop_words = 'english')\n",
    "    # Fit and transform the data with Count Vectorizer\n",
    "    data_tf = tf.fit_transform(data).todense()\n",
    "    # Change it into dataframe\n",
    "    data_tf_df = pd.DataFrame(data_tf, columns = tf.get_feature_names())\n",
    "    \n",
    "    # Get a column containing the count of words called total and \n",
    "    # create a new dataframe with only the total and word columns\n",
    "    data_total = pd.DataFrame(data_tf_df.sum(axis=0), columns=['total']).reset_index()\n",
    "    data_total.rename({'index': 'word'}, axis=1, inplace=True)\n",
    "    \n",
    "    # Get the top words in the speeches\n",
    "    top_data = data_total.sort_values(by='total', ascending=False).head(num)\n",
    "    return top_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_persuasive_inaccuracies = count_words(persuasive_inaccurate['speech'],20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='total', y='word', data=top_persuasive_inaccuracies, palette='BuPu_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out the correctly predicted ones\n",
    "persuasive_accurate = model_eval[model_eval['predictions'] == 1]\n",
    "persuasive_accurate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_persuasive_accuracies = count_words(persuasive_accurate['speech'], 20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='total', y='word', data=top_accuracies, palette='BuPu_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspiring Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ted_model.transcript\n",
    "y_train = ted_model.inspiring_label\n",
    "\n",
    "X_test = speeches.speech\n",
    "y_test = speeches.inspiring_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'tf__min_df': 2, 'tf__max_features': 2500, 'tf__max_df': 0.8, 'logreg__penalty': 'l2', 'logreg__class_weight': None}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623482</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.624324</td>\n",
       "      <td>0.623482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'tf__min_df': 2, 'tf__max_features': 2500, 'tf__max_df': 0.7, 'svm__penalty': 'l2', 'svm__max_iter': 5, 'svm__loss': 'log', 'svm__alpha': 0.001}</td>\n",
       "      <td>0.818656</td>\n",
       "      <td>0.678812</td>\n",
       "      <td>0.638814</td>\n",
       "      <td>0.695015</td>\n",
       "      <td>0.665730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  \\\n",
       "0  logreg   \n",
       "1     svm   \n",
       "\n",
       "                                                                                                                                         best_params  \\\n",
       "0                              {'tf__min_df': 2, 'tf__max_features': 2500, 'tf__max_df': 0.8, 'logreg__penalty': 'l2', 'logreg__class_weight': None}   \n",
       "1  {'tf__min_df': 2, 'tf__max_features': 2500, 'tf__max_df': 0.7, 'svm__penalty': 'l2', 'svm__max_iter': 5, 'svm__loss': 'log', 'svm__alpha': 0.001}   \n",
       "\n",
       "   train_accuracy  test_accuracy    recall  precision  f1-score  \n",
       "0        1.000000       0.623482  0.622642   0.624324  0.623482  \n",
       "1        0.818656       0.678812  0.638814   0.695015  0.665730  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best parameters to instantiate model\n",
    "inspiring_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.425\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with best parameters.\n",
    "tf_final = TfidfVectorizer(min_df=2, max_features=2500, max_df=0.7, \n",
    "                           stop_words='english', ngram_range=(1,2))\n",
    "X_train_final = tf_final.fit_transform(X_train)\n",
    "X_test_final = tf_final.transform(X_test)\n",
    "\n",
    "# Fit model.\n",
    "svm_final = SGDClassifier(penalty='l2', max_iter=5, loss='log', alpha=0.001, random_state=42)\n",
    "svm_final.fit(X_train_final, y_train)\n",
    "print('Accuracy score: ', svm_final.score(X_test_final, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = svm_final.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame(speeches['title'])\n",
    "model_eval['speech'] = X_test\n",
    "model_eval['label'] = y_test\n",
    "model_eval['predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a dream by MLK</td>\n",
       "      <td>dream one day alabama vicious racist governor lip dripping word interposition nullification one day right alabama little black boy black girl able join hand little white boy white girl sister brot...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tilbury Speech by Queen Elizabeth I</td>\n",
       "      <td>loving people persuaded careful safety take heed commit self armed multitude fear treachery assure desire live distrust faithful loving people let tyrant fear always behaved god placed chiefest st...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woodrow Wilson, address to Congress (April</td>\n",
       "      <td>world must made safe democracy peace must planted upon tested foundation political liberty selfish end serve desire conquest dominion seek indemnity material compensation sacrifice shall freely ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ain’t I A Woman by Sojourner Truth</td>\n",
       "      <td>man say woman need helped carriage lifted ditch best place everywhere nobody ever help carriage mud puddle give best place woman look look arm ploughed planted gathered barn man could head woman c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Gettsyburg Address by Abraham Lincoln</td>\n",
       "      <td>fondly hope fervently pray mighty scourge war may speedily pas away yet god will continue wealth piled bondsman two hundred fifty year unrequited toil shall sunk every drop blood drawn lash shall ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                          I have a dream by MLK   \n",
       "1            Tilbury Speech by Queen Elizabeth I   \n",
       "2   Woodrow Wilson, address to Congress (April     \n",
       "3             Ain’t I A Woman by Sojourner Truth   \n",
       "4      The Gettsyburg Address by Abraham Lincoln   \n",
       "\n",
       "                                                                                                                                                                                                    speech  \\\n",
       "0  dream one day alabama vicious racist governor lip dripping word interposition nullification one day right alabama little black boy black girl able join hand little white boy white girl sister brot...   \n",
       "1  loving people persuaded careful safety take heed commit self armed multitude fear treachery assure desire live distrust faithful loving people let tyrant fear always behaved god placed chiefest st...   \n",
       "2  world must made safe democracy peace must planted upon tested foundation political liberty selfish end serve desire conquest dominion seek indemnity material compensation sacrifice shall freely ma...   \n",
       "3  man say woman need helped carriage lifted ditch best place everywhere nobody ever help carriage mud puddle give best place woman look look arm ploughed planted gathered barn man could head woman c...   \n",
       "4  fondly hope fervently pray mighty scourge war may speedily pas away yet god will continue wealth piled bondsman two hundred fifty year unrequited toil shall sunk every drop blood drawn lash shall ...   \n",
       "\n",
       "   label  predictions  \n",
       "0      1            1  \n",
       "1      1            0  \n",
       "2      1            1  \n",
       "3      1            1  \n",
       "4      1            0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataframe\n",
    "model_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tilbury Speech by Queen Elizabeth I</td>\n",
       "      <td>loving people persuaded careful safety take heed commit self armed multitude fear treachery assure desire live distrust faithful loving people let tyrant fear always behaved god placed chiefest st...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Gettsyburg Address by Abraham Lincoln</td>\n",
       "      <td>fondly hope fervently pray mighty scourge war may speedily pas away yet god will continue wealth piled bondsman two hundred fifty year unrequited toil shall sunk every drop blood drawn lash shall ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vladimir Lenin’s Speech at an International Meeting in Berne, February</td>\n",
       "      <td>may sound incredible especially swiss comrade nevertheless true russia also bloody tsarism capitalist also section called ex socialist say russia fighting war defence russia fighting german invasi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>First Inaugural Speech by Franklin D Roosevelt</td>\n",
       "      <td>first let assert firm belief thing fear fear nameless unreasoning unjustified terror paralyzes needed effort convert retreat advance every dark hour national life leadership frankness vigor met un...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hypocrisy of American Slavery by Frederick Douglass</td>\n",
       "      <td>american slave fourth july answer day reveals day year gross injustice cruelty constant victim celebration sham boasted liberty unholy license national greatness swelling vanity sound rejoicing em...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       title  \\\n",
       "1                                        Tilbury Speech by Queen Elizabeth I   \n",
       "4                                  The Gettsyburg Address by Abraham Lincoln   \n",
       "6   Vladimir Lenin’s Speech at an International Meeting in Berne, February     \n",
       "8                             First Inaugural Speech by Franklin D Roosevelt   \n",
       "9                    The Hypocrisy of American Slavery by Frederick Douglass   \n",
       "\n",
       "                                                                                                                                                                                                    speech  \\\n",
       "1  loving people persuaded careful safety take heed commit self armed multitude fear treachery assure desire live distrust faithful loving people let tyrant fear always behaved god placed chiefest st...   \n",
       "4  fondly hope fervently pray mighty scourge war may speedily pas away yet god will continue wealth piled bondsman two hundred fifty year unrequited toil shall sunk every drop blood drawn lash shall ...   \n",
       "6  may sound incredible especially swiss comrade nevertheless true russia also bloody tsarism capitalist also section called ex socialist say russia fighting war defence russia fighting german invasi...   \n",
       "8  first let assert firm belief thing fear fear nameless unreasoning unjustified terror paralyzes needed effort convert retreat advance every dark hour national life leadership frankness vigor met un...   \n",
       "9  american slave fourth july answer day reveals day year gross injustice cruelty constant victim celebration sham boasted liberty unholy license national greatness swelling vanity sound rejoicing em...   \n",
       "\n",
       "   label  predictions  \n",
       "1      1            0  \n",
       "4      1            0  \n",
       "6      1            0  \n",
       "8      1            0  \n",
       "9      1            0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick out the incorrectly predicted ones\n",
    "inspiring_inaccurate = model_eval[model_eval['predictions'] == 0]\n",
    "inspiring_inaccurate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_inspiring_inaccuracies = count_words(inspiring_inaccurate['speech'],20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='total', y='word', data=top_inspiring_inaccuracies, palette='plasma');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a dream by MLK</td>\n",
       "      <td>dream one day alabama vicious racist governor lip dripping word interposition nullification one day right alabama little black boy black girl able join hand little white boy white girl sister brot...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woodrow Wilson, address to Congress (April</td>\n",
       "      <td>world must made safe democracy peace must planted upon tested foundation political liberty selfish end serve desire conquest dominion seek indemnity material compensation sacrifice shall freely ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ain’t I A Woman by Sojourner Truth</td>\n",
       "      <td>man say woman need helped carriage lifted ditch best place everywhere nobody ever help carriage mud puddle give best place woman look look arm ploughed planted gathered barn man could head woman c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Woman’s Rights to the Suffrage by Susan B Anthony</td>\n",
       "      <td>state make sex qualification must ever result disfranchisement one entire half people pas bill attainder ex post facto law therefore violation supreme law land blessing liberty ever withheld woman...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I Have A Dream Speech by Mary Wollstonecraft</td>\n",
       "      <td>say would impress declamation reason offer sober light really capable acting like rational creature let treated like slave like brute dependent reason man associate cultivate mind give salutary su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                               I have a dream by MLK   \n",
       "2        Woodrow Wilson, address to Congress (April     \n",
       "3                  Ain’t I A Woman by Sojourner Truth   \n",
       "5   Woman’s Rights to the Suffrage by Susan B Anthony   \n",
       "7        I Have A Dream Speech by Mary Wollstonecraft   \n",
       "\n",
       "                                                                                                                                                                                                    speech  \\\n",
       "0  dream one day alabama vicious racist governor lip dripping word interposition nullification one day right alabama little black boy black girl able join hand little white boy white girl sister brot...   \n",
       "2  world must made safe democracy peace must planted upon tested foundation political liberty selfish end serve desire conquest dominion seek indemnity material compensation sacrifice shall freely ma...   \n",
       "3  man say woman need helped carriage lifted ditch best place everywhere nobody ever help carriage mud puddle give best place woman look look arm ploughed planted gathered barn man could head woman c...   \n",
       "5  state make sex qualification must ever result disfranchisement one entire half people pas bill attainder ex post facto law therefore violation supreme law land blessing liberty ever withheld woman...   \n",
       "7  say would impress declamation reason offer sober light really capable acting like rational creature let treated like slave like brute dependent reason man associate cultivate mind give salutary su...   \n",
       "\n",
       "   label  predictions  \n",
       "0      1            1  \n",
       "2      1            1  \n",
       "3      1            1  \n",
       "5      1            1  \n",
       "7      1            1  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick out the correctly predicted ones\n",
    "inspiring_accurate = model_eval[model_eval['predictions'] == 1]\n",
    "inspiring_accurate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_inspiring_accuracies = count_words(inspiring_accurate['speech'], 20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='total', y='word', data=top_inspiring_accuracies, palette='plasma');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14dextract SVM feature importance sklearn sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconvincing Classifier Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this classifier, we will evaluate it using our original dataset with train/ test split and see the accuracy of the prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ted_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49b9b2c8653e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconvincing_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ted_model' is not defined"
     ]
    }
   ],
   "source": [
    "X = ted_model.transcript\n",
    "y = ted_model.unconvincing_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test data - get predict proba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconvincing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "\n",
    "# create plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "colors = [‘red’ if c < 0 else ‘blue’ for c in coef[top_coefficients]]\n",
    "plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "feature_names = np.array(feature_names)\n",
    "plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=’right’)\n",
    "plt.show()\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "tvec.fit(data)\n",
    "print len(cv.vocabulary_)\n",
    "print cv.get_feature_names()\n",
    "X_train = cv.transform(data)\n",
    "\n",
    "svm = SGDClassfier()\n",
    "svm.fit(X_train, target)\n",
    "plot_coefficients(svm, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
